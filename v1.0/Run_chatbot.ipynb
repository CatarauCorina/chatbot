{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from chatbot import ChatBot\n",
    "\n",
    "from data_preproc import DataPreprocessor, DataCleaner\n",
    "\n",
    "\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=self.device, dtype=torch.long) * 1\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=self.device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=self.device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores\n",
    "\n",
    "\n",
    "def evaluate(searcher, voc, sentence, chatbot, max_length=10):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    USE_CUDA = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "    indexes_batch = [chatbot.data_loader.transform_sentence_word_indexes(sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(searcher, voc,chatbot):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = chatbot.dc.normalize_string(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(searcher, voc, input_sentence, chatbot)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    checkpoint_file = os.path.join('checkpoints', '8000_checkpoint.tar')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
    "\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    chatbot_dict = {\n",
    "        'pretrained_embedding': True,\n",
    "        'pretrained_embedding_file': embedding_sd,\n",
    "        'pretrained_enc_dec': True,\n",
    "        'pretrained_enc_file': encoder_sd,\n",
    "        'pretrained_dec_file': decoder_sd\n",
    "    }\n",
    "    chatbot = ChatBot(**chatbot_dict)\n",
    "    chatbot.dc.vocabulary.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "    chatbot.encoder.eval()\n",
    "    chatbot.decoder.eval()\n",
    "\n",
    "    searcher = GreedySearchDecoder(chatbot.encoder, chatbot.decoder)\n",
    "\n",
    "    evaluateInput(\n",
    "        searcher=searcher,\n",
    "        voc=chatbot.dc.vocabulary,\n",
    "        chatbot=chatbot)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed long sentences 64271 sentence pairs\n",
      "Counted words: 18008\n",
      "Trimmed from 64271 pairs to 53165 of total\n",
      "> hi\n",
      "Bot: hi . .\n",
      "> how are you ?\n",
      "Bot: okay . . .\n",
      "> where are you ?\n",
      "Bot: i m . .\n",
      "> yes ?\n",
      "Bot: i . .\n",
      "> what do you like ?\n",
      "Bot: i . . . . . . .\n",
      "> favourite movie ?\n",
      "Bot: i . . . . . .\n",
      "> what do you like\n",
      "Bot: you re . . . . . .\n",
      "> ok\n",
      "Bot: i m t .\n",
      "> what\n",
      "Bot: what s the throbbing ?\n",
      "> not making a lot of sense\n",
      "Bot: when when i mean . . .\n",
      "> are we friends ?\n",
      "Bot: yes . . . . . . .\n",
      "> great\n",
      "Bot: you you . ?\n",
      "> where are you from?\n",
      "Bot: south .\n",
      "> what do you eat?\n",
      "Bot: i don t . . . . .\n",
      "> why?\n",
      "Bot: because i t . . .\n",
      "> you're under arrest\n",
      "Bot: i m t . .\n",
      "> ciao\n",
      "Error: Encountered unknown word.\n",
      "> qui\n",
      "Error: Encountered unknown word.\n",
      "> ola\n",
      "Error: Encountered unknown word.\n",
      "> so ?\n",
      "Bot: so i t . . .\n",
      "> what's your name?\n",
      "Bot: mary . . .\n",
      "> Mary ?\n",
      "Bot: oh .\n",
      "> tell me something?\n",
      "Bot: i . . . . .\n",
      "> awful\n",
      "Bot: i m .\n",
      "> yes you\n",
      "Bot: i . . .\n",
      "> hello and good bye\n",
      "Bot: good . . . . . . .\n",
      "> bad\n",
      "Bot: how ?\n",
      "> very\n",
      "Bot: and you is to . .\n",
      "> bye\n",
      "Bot: bye . . .\n",
      "> quit\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
